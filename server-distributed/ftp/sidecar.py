import os
import shutil
import threading
import time
from ftp.alias_discovery import start_alias_discovery
from ftp.cluster_comm import start_cluster_communication
from ftp.state_manager import get_state_manager
from ftp.bully_election import BullyElection
from ftp.leader_operations import process_local_leader_request, get_leader_operations
from ftp.node_transfer import get_node_transfer

# Variables globales
_cluster_comm_global = None
_bully_instance = None

def start_sidecar():
    global _cluster_comm_global, _bully_instance
    print(">>> Iniciando Sidecar...")
    node_id = os.environ.get('NODE_ID', 'unknown')
    
    discovery = start_alias_discovery()
    initial_ips = discovery.get_cluster_ips()
    _cluster_comm_global = start_cluster_communication(node_id, initial_ips)
    state_mgr = get_state_manager(node_id)

    # Iniciar Bully
    local_ip = _cluster_comm_global.local_ip
    _bully_instance = BullyElection(node_id, local_ip, _cluster_comm_global, state_mgr)
    
    # Registrar handlers
    _cluster_comm_global.register_handler('ELECTION', _bully_instance.handle_election_msg)
    _cluster_comm_global.register_handler('COORDINATOR', _bully_instance.handle_coordinator_msg)
    _cluster_comm_global.register_handler('REQUEST_LOGS', handle_request_logs)
    _cluster_comm_global.register_handler('SYNC_COMMANDS', handle_sync_commands)
    _cluster_comm_global.register_handler('FS_REQUEST', handle_fs_request)
    _cluster_comm_global.register_handler('FS_ORDER', handle_fs_order)
    _cluster_comm_global.register_handler('MKD_NOTIFY', handle_mkd_notify)
    _cluster_comm_global.register_handler('REPLICA_SUCCESS', handle_replica_success)
    _cluster_comm_global.register_handler('REQUEST_DISK_SCAN', handle_request_disk_scan)
    _cluster_comm_global.register_handler('DELTA_CONFIRMATION', handle_delta_confirmation)

    discovery.set_ips_change_callback(update_ips_callback)
    if initial_ips: update_ips_callback(initial_ips)
    
    get_node_transfer(local_ip) # Iniciar transfer server
    
    if _bully_instance.am_i_leader():
        get_leader_operations(_cluster_comm_global, _bully_instance)

    # Iniciar el verificador de replicaci√≥n en un hilo separado
    threading.Thread(target=start_replication_checker, daemon=True).start()
    threading.Thread(target=start_periodic_zombie_cleanup, daemon=True).start()

    return _cluster_comm_global

# --- HANDLERS PRINCIPALES ---

def handle_fs_order(message):
    """Este nodo (actuando como R√âPLICA) recibe una orden del l√≠der."""
    
    command = message.get('command')
    path = message.get('path')
    operation_id = message.get('operation_id')
    check_empty = message.get('check_empty', False)
    
    state_mgr = get_state_manager()
    
    try:
        if command == 'CREATE_DIR':
            create_and_log_dirs(
                path,
                state_mgr,
                _cluster_comm_global.local_ip,
                operation_id
            )
            return {'status': 'ok', 'message': 'Directory created'}
            
        elif command == 'DELETE_DIR':
            # Funci√≥n auxiliar para identificar archivos basura internos
            def _is_junk_file(filename):
                # Patrones de archivos temporales creados por APPE o transferencias
                return '.delta.' in filename or '.tmp.' in filename or filename.endswith('.tmp')

            try:
                if os.path.exists(path) and os.path.isdir(path):
                    # 1. Limpieza proactiva de artefactos internos (Deltas huerfanos)
                    # Si el usuario ya borr√≥ los archivos reales, estos deltas sobran.
                    try:
                        for f in os.listdir(path):
                            if _is_junk_file(f):
                                full_junk_path = os.path.join(path, f)
                                try:
                                    os.remove(full_junk_path)
                                    print(f"[ORDER] üßπ Limpieza autom√°tica de artefacto interno: {f}")
                                except OSError:
                                    pass # Si no se puede borrar (bloqueado), lo dejamos y fallar√° el rmdir
                    except Exception as e:
                        print(f"[ORDER] Advertencia durante limpieza de deltas: {e}")

                    # 2. Verificar si est√° vac√≠o (ahora ignorando los deltas que acabamos de borrar)
                    if check_empty and os.listdir(path):
                        # Si todav√≠a queda algo (archivos reales del usuario), error.
                        return {'status': 'error', 'message': 'Directory not empty'}
                    
                    # 3. Borrar directorio
                    os.rmdir(path)
                    print(f"[ORDER] Directorio eliminado: {path}")
                    
                    state_mgr.append_operation('RMD', path, {
                        'operation_id': operation_id,
                        'executed_by': _cluster_comm_global.local_ip,
                        'from_order': True
                    })
                    
                    return {'status': 'ok', 'message': 'Directory deleted'}
                else:
                    # Idempotencia: Si ya no existe, damos OK
                    state_mgr.append_operation('RMD', path, {
                        'operation_id': operation_id,
                        'executed_by': _cluster_comm_global.local_ip,
                        'already_gone': True
                    })
                    return {'status': 'ok', 'message': 'Directory already removed'}
                    
            except Exception as e:
                print(f"[ORDER] Error eliminando directorio {path}: {e}")
                return {'status': 'error', 'message': str(e)}
            
        elif command == 'APPEND_BLOCK':
            delta_source = message.get('delta_source')
            delta_remote_path = message.get('delta_path')
            target_path = message.get('path')
            requester = message.get('requester')
            
            print(f"[SIDECAR] Orden APPEND_BLOCK recibida para {target_path}")
            print(f"[SIDECAR]   - Delta source: {delta_source}")
            print(f"[SIDECAR]   - Delta path: {delta_remote_path}")
            
            if not os.path.exists(target_path):
                print(f"[SIDECAR] Error APPEND: No tengo el archivo original {target_path}")
                return {'status': 'error', 'message': 'Original file missing'}
            
            # Descargar el delta
            local_delta_temp = target_path + f".delta_incoming.{time.time()}"
            
            from ftp.node_transfer import get_node_transfer
            transfer = get_node_transfer()
            
            print(f"[SIDECAR] Descargando delta desde {delta_source}...")
            success, _, msg = transfer.request_file_from_node(
                delta_source, delta_remote_path, local_delta_temp
            )
            
            if success:
                try:
                    # Hacer append
                    print(f"[SIDECAR] Aplicando append en {target_path}...")
                    with open(target_path, 'ab') as target, open(local_delta_temp, 'rb') as delta:
                        while True:
                            chunk = delta.read(1024*1024)
                            if not chunk: break
                            target.write(chunk)
                    
                    print(f"[SIDECAR] Append aplicado exitosamente en {target_path}")
                    
                    # Limpiar delta temporal
                    os.remove(local_delta_temp)
                    
                    # Enviar confirmaci√≥n al nodo que envi√≥ la orden
                    try:
                        print(f"[SIDECAR] Enviando confirmaci√≥n de append a {requester}")
                        confirmation_msg = {
                            'type': 'DELTA_CONFIRMATION',
                            'delta_path': delta_remote_path,
                            'node_ip': _cluster_comm_global.local_ip,
                            'target_path': target_path,
                            'status': 'success',
                            'timestamp': time.time()
                        }
                        
                        # Enviar confirmaci√≥n (non-blocking)
                        threading.Thread(
                            target=_cluster_comm_global.send_message,
                            args=(requester, confirmation_msg, False),
                            daemon=True
                        ).start()
                        
                    except Exception as e:
                        print(f"[SIDECAR] Error enviando confirmaci√≥n: {e}")
                    
                    return {'status': 'ok'}
                    
                except Exception as e:
                    print(f"[SIDECAR] Error escribiendo append: {e}")
                    # Intentar limpiar delta temporal
                    try:
                        if os.path.exists(local_delta_temp):
                            os.remove(local_delta_temp)
                    except:
                        pass
                    return {'status': 'error', 'message': str(e)}
            else:
                print(f"[SIDECAR] Fallo descargando delta desde {delta_source}: {msg}")
                return {'status': 'error', 'message': f'Failed to download delta: {msg}'}

        elif command == 'RENAME':
            old_path = message.get('old_path')
            new_path = message.get('new_path')
            operation_id = message.get('operation_id')
            item_type = message.get('item_type', 'file')
            is_directory = message.get('is_directory', False)
            must_execute_on_all = message.get('must_execute_on_all', False)
            
            print(f"[ORDER] RENAME recibido: {old_path} -> {new_path} (tipo: {item_type}, directorio: {is_directory})")
            
            # Si es un directorio, DEBEMOS ejecutarlo aunque no tengamos el archivo
            if is_directory and must_execute_on_all:
                print(f"[ORDER] Directorio - EJECUTANDO en todos los nodos: {old_path} -> {new_path}")
            
            try:
                # Para directorios, manejamos de forma especial
                if is_directory:
                    success = _handle_directory_rename(old_path, new_path, operation_id)
                    
                    # CR√çTICO: Despu√©s de renombrar, limpiar cualquier estructura antigua que haya quedado
                    if success and os.path.exists(old_path):
                        print(f"[ORDER] Estructura antigua detectada despu√©s de renombrado: {old_path}")
                        try:
                            # Intentar eliminar la estructura antigua
                            if os.path.isdir(old_path):
                                # Verificar si tiene contenido
                                contents = os.listdir(old_path)
                                if contents:
                                    print(f"[ORDER] Estructura antigua tiene {len(contents)} elementos, limpiando...")
                                    shutil.rmtree(old_path)
                                    print(f"[ORDER] Estructura antigua eliminada: {old_path}")
                                else:
                                    os.rmdir(old_path)
                                    print(f"[ORDER] Directorio vac√≠o antiguo eliminado: {old_path}")
                        except Exception as cleanup_error:
                            print(f"[ORDER] No se pudo limpiar estructura antigua: {cleanup_error}")
                            # No fallar la operaci√≥n por esto
                else:
                    success = _handle_file_rename(old_path, new_path, operation_id, message)
                
                if success:
                    # Actualizar nuestro state manager local
                    state_mgr = get_state_manager()
                    with state_mgr.lock:
                        # Si tenemos entrada para el archivo/directorio viejo, moverla
                        if old_path in state_mgr.file_map:
                            state_mgr.file_map[new_path] = state_mgr.file_map[old_path]
                            del state_mgr.file_map[old_path]
                            
                            # Si es un directorio, actualizar rutas hijas
                            if is_directory:
                                old_prefix = old_path.rstrip('/') + '/'
                                new_prefix = new_path.rstrip('/') + '/'
                                
                                keys_to_update = [k for k in list(state_mgr.file_map.keys()) 
                                                if k.startswith(old_prefix)]
                                
                                for old_key in keys_to_update:
                                    relative_part = old_key[len(old_prefix):]
                                    new_key = new_prefix + relative_part
                                    
                                    if old_key in state_mgr.file_map:
                                        state_mgr.file_map[new_key] = state_mgr.file_map[old_key]
                                        del state_mgr.file_map[old_key]
                    
                    # Registrar en log local
                    state_mgr.append_operation('RN', new_path, {
                        'old_path': old_path,
                        'operation_id': operation_id,
                        'executed_by': _cluster_comm_global.local_ip,
                        'from_order': True,
                        'item_type': item_type,
                        'success': success
                    })
                    
                    return {'status': 'ok', 'message': 'Renamed successfully'}
                
                else:
                    # SI FALL√ì (por busy u otro), NO tocamos el mapa local y avisamos error
                    return {'status': 'error', 'message': 'Rename failed on disk (File Busy or Error)'}
                
            except Exception as e:
                print(f"[ORDER] Error en RENAME {old_path} -> {new_path}: {e}")
                import traceback
                traceback.print_exc()
                
                # Registrar error en log
                state_mgr = get_state_manager()
                state_mgr.append_operation('RN', new_path, {
                    'old_path': old_path,
                    'operation_id': operation_id,
                    'executed_by': _cluster_comm_global.local_ip,
                    'error': str(e),
                    'failed': True
                })
                
                return {'status': 'error', 'message': str(e)}

        elif command == 'DELETE_FILE':
            try:
                if os.path.exists(path) and os.path.isfile(path):
                    os.remove(path)
                    print(f"[ORDER] Archivo eliminado: {path}")
                    
                    state_mgr.append_operation('DELE', path, {
                        'operation_id': operation_id,
                        'executed_by': _cluster_comm_global.local_ip,
                        'from_order': True
                    })
                    
                    return {'status': 'ok', 'message': 'File deleted'}
                else:
                    # Si no existe, a√∫n as√≠ registrar la operaci√≥n
                    state_mgr.append_operation('DELE', path, {
                        'operation_id': operation_id,
                        'executed_by': _cluster_comm_global.local_ip,
                        'already_gone': True
                    })
                    return {'status': 'ok', 'message': 'File already removed'}
                    
            except Exception as e:
                print(f"[ORDER] Error eliminando archivo {path}: {e}")
                return {'status': 'error', 'message': str(e)}    

        elif command == 'REPLICATE_FILE':
            source_ip = message.get('source')
            file_size = message.get('size')
            file_hash = message.get('hash')
            is_repair = message.get('is_repair', False)
            repair_type = message.get('repair_type', '')
            failed_node = message.get('failed_node', '')
            from_leader = message.get('from_leader', False)
            operation_id = message.get('operation_id', '')
            
            print(f"[SIDECAR] Orden REPLICATE_FILE recibida para {path} desde {source_ip}")
            
            # 1. Asegurar directorios
            dir_path = os.path.dirname(path)
            if dir_path:
                os.makedirs(dir_path, exist_ok=True)
            
            # 2. Transferir archivo
            from ftp.node_transfer import get_node_transfer
            transfer = get_node_transfer()
            
            max_retries = 3
            for attempt in range(max_retries):
                success, actual_path, msg = transfer.request_file_from_node(source_ip, path, path)
                
                if success:
                    # 3. Registrar operaci√≥n STOR en el log local
                    metadata = {
                        'size': file_size,
                        'hash': file_hash,
                        'replicas': [source_ip, _cluster_comm_global.local_ip],
                        'operation_id': operation_id,
                        'from_replication': True,
                        'timestamp': time.time(),
                        'source_node': source_ip
                    }
                    
                    # CORRECCI√ìN: Usar state_mgr que ya tenemos
                    state_mgr.append_operation('STOR', path, metadata)
                    
                    # 4. Actualizar file_map local
                    if path not in state_mgr.file_map:
                        state_mgr.file_map[path] = {
                            'type': 'file',
                            'size': file_size,
                            'hash': file_hash,
                            'replicas': [source_ip, _cluster_comm_global.local_ip],
                            'mtime': time.time()
                        }
                    else:
                        # Asegurar que estamos en la lista de r√©plicas
                        if _cluster_comm_global.local_ip not in state_mgr.file_map[path].get('replicas', []):
                            state_mgr.file_map[path]['replicas'].append(_cluster_comm_global.local_ip)
                    
                    print(f"[SIDECAR] R√©plica exitosa: {path}")
                    
                    # 5. Notificar al l√≠der si es reparaci√≥n
                    if is_repair and not from_leader and _bully_instance and not _bully_instance.am_i_leader():
                        leader_ip = _bully_instance.get_leader()
                        if leader_ip:
                            try:
                                notify_msg = {
                                    'type': 'REPLICA_SUCCESS',
                                    'path': path,
                                    'node_ip': _cluster_comm_global.local_ip,
                                    'timestamp': time.time(),
                                    'repair_type': repair_type,
                                    'failed_node': failed_node
                                }
                                _cluster_comm_global.send_message(leader_ip, notify_msg, expect_response=False)
                            except Exception as e:
                                print(f"[SIDECAR] Error notificando r√©plica exitosa: {e}")
                    
                    return {'status': 'ok', 'message': 'File replicated'}
                else:
                    print(f"[SIDECAR] Intento {attempt + 1} fall√≥ para {path}: {msg}")
                    if attempt < max_retries - 1:
                        time.sleep(1)
            
            print(f"[SIDECAR] Fallo en r√©plica de {path} despu√©s de {max_retries} intentos")
            return {'status': 'error', 'message': f'Replication failed after {max_retries} attempts'}
        
        else:
            print(f"[ORDER] Comando desconocido: {command}")
            return {'status': 'error', 'message': f'Unknown command: {command}'}

    except Exception as e:
        print(f"[ORDER] Error: {e}")
        import traceback
        traceback.print_exc()
        return {'status': 'error', 'message': str(e)}

def handle_fs_request(message):
    """
    Este nodo (actuando como L√çDER) recibe una petici√≥n de un cliente (via otro nodo).
    """
    msg_type = message.get('subtype')
    data = message.get('data', {})
    # Esta funci√≥n llama a LeaderOperations
    return process_local_leader_request(msg_type, data)

def handle_mkd_notify(message):
    """
    Mensaje esperado: {'path': <abs_path>, 'node_ip': <ip>}
    El l√≠der a√±ade la IP como replica de forma inmediata.
    """
    try:
        path = message.get('path')
        node_ip = message.get('node_ip')
        sm = get_state_manager()
        with sm.lock:
            # Aseguramos entrada en file_map
            if path not in sm.file_map:
                sm.file_map[path] = {
                    'type': 'dir',
                    'mtime': time.time(),
                    'replicas': []
                }
            # A√±adir si no estaba
            if node_ip not in sm.file_map[path]['replicas']:
                sm.file_map[path]['replicas'].append(node_ip)
                print(f"[LIDER] MKD_NOTIFY -> a√±adido replica {node_ip} para {path}")
        return {'status': 'ok'}
    except Exception as e:
        print(f"[LIDER] Error en handle_mkd_notify: {e}")
        return {'status': 'error', 'message': str(e)}

def handle_request_logs(message):
    """El nuevo l√≠der pide mis logs para reconstruir el esquema."""
    sm = get_state_manager()
    return {
        'status': 'ok', 
        'log': sm.get_full_log_as_dict(),
        'node_ip': _cluster_comm_global.local_ip
    }

def handle_sync_commands(message):
    """
    Ejecuta comandos de sincronizaci√≥n enviados por el l√≠der.
    """
    commands = message.get('commands', [])
    print(f"[SIDECAR] Recibidos {len(commands)} comandos de sincronizaci√≥n")
    
    results = []
    
    for cmd in commands:
        command = cmd.get('command')
        path = cmd.get('path')
        reason = cmd.get('reason', '')
        
        try:
            if command == 'DELETE_FILE':
                if os.path.exists(path) and os.path.isfile(path):
                    os.remove(path)
                    print(f"[SYNC] Zombi eliminado: {path}")
                    # Registrar en log local para no volver a resucitarlo si reiniciamos
                    get_state_manager().append_operation('DELE', path, {'zombie_purge': True})
                    results.append({
                        'command': command,
                        'path': path,
                        'status': 'deleted',
                        'reason': reason
                    })
                else:
                    results.append({
                        'command': command,
                        'path': path,
                        'status': 'already_gone'
                    })
    
            elif command == 'CREATE_FILE' or command == 'UPDATE_FILE':
                # CREACI√ìN/ACTUALIZACI√ìN DE ARCHIVO CON LAST WRITE WINS
                replicas = cmd.get('replicas', [])
                expected_size = cmd.get('size', 0)
                expected_hash = cmd.get('hash', '')
                global_mtime = cmd.get('global_mtime', 0)
                
                # Excluir al nodo local de la lista de r√©plicas
                replicas = [ip for ip in replicas if ip != _cluster_comm_global.local_ip]
                
                if not replicas:
                    print(f"[SYNC] {command} {path} - No hay r√©plicas disponibles")
                    results.append({
                        'command': command, 
                        'path': path, 
                        'status': 'error', 
                        'error': 'No replicas available'
                    })
                    continue
                
                # Verificar si ya existe y comparar timestamps
                if os.path.exists(path):
                    existing_mtime = os.path.getmtime(path)
                    existing_size = os.path.getsize(path)
                    
                    print(f"[SYNC] {command} {path} - Archivo existe (mtime local: {existing_mtime}, global: {global_mtime})")
                    
                    # Last Write Wins: Solo reemplazar si el global es M√ÅS RECIENTE
                    if command == 'UPDATE_FILE' and global_mtime > 0 and existing_mtime >= global_mtime:
                        print(f"[SYNC] {command} {path} - Versi√≥n local es igual o m√°s reciente. CONSERVANDO local.")
                        results.append({
                            'command': command,
                            'path': path,
                            'status': 'kept_local',
                            'reason': 'local_version_newer_or_equal',
                            'local_mtime': existing_mtime,
                            'global_mtime': global_mtime
                        })
                        continue
                    
                    # Si es CREATE_FILE y el archivo existe, conservarlo (no deber√≠a pasar)
                    if command == 'CREATE_FILE':
                        print(f"[SYNC] {command} {path} - Archivo ya existe. CONSERVANDO (no deber√≠a pasar).")
                        results.append({
                            'command': command,
                            'path': path,
                            'status': 'already_exists',
                            'size': existing_size
                        })
                        continue
                    
                    # Si llegamos aqu√≠, el global es m√°s reciente - proceder con actualizaci√≥n
                    print(f"[SYNC] {command} {path} - Versi√≥n global m√°s reciente. Actualizando...")
                
                print(f"[SYNC] {command} {path} - Descargando de r√©plica (Raz√≥n: {reason})")
                
                success = False
                last_error = ""
                
                for replica_ip in replicas:
                    try:
                        from ftp.node_transfer import get_node_transfer
                        transfer = get_node_transfer()
                        
                        # Descargar a temporal primero
                        temp_path = f"{path}.tmp.{int(time.time())}"
                        success, actual_path, msg = transfer.request_file_from_node(replica_ip, path, temp_path)
                        
                        if success:
                            # Verificar tama√±o
                            if expected_size > 0:
                                actual_size = os.path.getsize(temp_path)
                                if actual_size != expected_size:
                                    print(f"[SYNC] {command} {path} - Tama√±o incorrecto: esperado={expected_size}, actual={actual_size}")
                                    os.remove(temp_path)
                                    success = False
                                    last_error = f"Size mismatch: {actual_size} vs {expected_size}"
                                    continue
                            
                            # Mover temporal a ubicaci√≥n final
                            if os.path.exists(path):
                                os.remove(path)
                            os.rename(temp_path, path)
                            
                            print(f"[SYNC] {command} {path} - Descargado exitosamente desde {replica_ip}")
                            break
                        else:
                            print(f"[SYNC] {command} {path} - Fall√≥ descarga desde {replica_ip}: {msg}")
                            last_error = msg
                    except Exception as e:
                        print(f"[SYNC] {command} {path} - Error con r√©plica {replica_ip}: {e}")
                        last_error = str(e)
                
                if success:
                    # Registrar en el log local
                    state_mgr = get_state_manager()
                    metadata = {
                        'size': expected_size,
                        'hash': expected_hash,
                        'from_sync': True,
                        'reason': reason,
                        'source_replica': replica_ip if success else None,
                        'command_type': command
                    }
                    
                    if command == 'UPDATE_FILE':
                        metadata['global_mtime'] = global_mtime
                    
                    state_mgr.append_operation('STOR', path, metadata)
                    
                    results.append({
                        'command': command, 
                        'path': path, 
                        'status': 'created' if command == 'CREATE_FILE' else 'updated',
                        'source': replica_ip if success else None
                    })
                else:
                    print(f"[SYNC] {command} {path} - No se pudo descargar de ninguna r√©plica")
                    results.append({
                        'command': command, 
                        'path': path, 
                        'status': 'error', 
                        'error': f'Failed to download from any replica: {last_error}'
                    })
                
            elif command == 'DELETE_DIR':
                # ELIMINACI√ìN DE DIRECTORIO ZOMBI
                if os.path.exists(path) and os.path.isdir(path):
                    # Intentar eliminar solo si est√° vac√≠o
                    try:
                        # Listar contenido
                        contents = os.listdir(path)
                        if contents:
                            print(f"[SYNC] DELETE_DIR {path} - No vac√≠o ({len(contents)} elementos), no se puede eliminar")
                            results.append({
                                'command': command, 
                                'path': path, 
                                'status': 'not_empty',
                                'item_count': len(contents)
                            })
                        else:
                            os.rmdir(path)
                            print(f"[SYNC] DELETE_DIR {path} - eliminado zombi (Raz√≥n: {reason})")
                            
                            # Registrar eliminaci√≥n en log local
                            state_mgr = get_state_manager()
                            state_mgr.append_operation('RMD', path, {
                                'from_sync': True,
                                'reason': reason,
                                'was_zombie': True,
                                'was_empty': True
                            })
                            
                            results.append({
                                'command': command, 
                                'path': path, 
                                'status': 'deleted',
                                'reason': reason
                            })
                    except OSError as e:
                        print(f"[SYNC] DELETE_DIR {path} - Error: {e}")
                        results.append({
                            'command': command, 
                            'path': path, 
                            'status': 'error', 
                            'error': str(e)
                        })
                else:
                    print(f"[SYNC] DELETE_DIR {path} - no exist√≠a")
                    results.append({
                        'command': command, 
                        'path': path, 
                        'status': 'already_gone',
                        'reason': reason
                    })

            elif command == 'DELETE_DIR_RECURSIVE':
                # Eliminaci√≥n recursiva de directorios obsoletos
                if os.path.exists(path) and os.path.isdir(path):
                    try:
                        print(f"[SYNC] Eliminando directorio obsoleto recursivamente: {path}")
                        print(f"[SYNC] Raz√≥n: {reason}")
                        
                        # Contar archivos antes de eliminar
                        file_count = sum(len(files) for _, _, files in os.walk(path))
                        
                        if file_count > 0:
                            print(f"[SYNC] Directorio contiene {file_count} archivos (todos obsoletos)")
                        
                        # Eliminar recursivamente
                        shutil.rmtree(path)
                        
                        print(f"[SYNC] Directorio obsoleto eliminado: {path} ({file_count} archivos)")
                        
                        # Registrar en log local
                        get_state_manager().append_operation('RMD', path, {
                            'zombie_purge': True,
                            'recursive': True,
                            'reason': reason,
                            'files_deleted': file_count
                        })
                        
                        results.append({
                            'command': command,
                            'path': path,
                            'status': 'deleted_recursive',
                            'files_deleted': file_count,
                            'reason': reason
                        })
                        
                    except Exception as e:
                        print(f"[SYNC] Error eliminando directorio recursivamente {path}: {e}")
                        results.append({
                            'command': command,
                            'path': path,
                            'status': 'error',
                            'error': str(e)
                        })
                else:
                    print(f"[SYNC] Directorio obsoleto {path} ya no existe")
                    results.append({
                        'command': command,
                        'path': path,
                        'status': 'already_gone'
                    })

            elif command == 'CREATE_DIR':
                # Creaci√≥n de directorio (existente)
                os.makedirs(path, exist_ok=True)
                print(f"[SYNC] CREATE_DIR {path} - creado/verificado (Raz√≥n: {reason})")
                
                # Registrar en log local
                state_mgr = get_state_manager()
                state_mgr.append_operation('MKD', path, {
                    'from_sync': True,
                    'reason': reason
                })
                
                results.append({
                    'command': command, 
                    'path': path, 
                    'status': 'created'
                })
                
            else:
                print(f"[SYNC] Comando desconocido: {command}")
                results.append({
                    'command': command, 
                    'path': path, 
                    'status': 'unknown'
                })
                
        except Exception as e:
            print(f"[SYNC] Error ejecutando {command} {path}: {e}")
            import traceback
            traceback.print_exc()
            results.append({
                'command': command, 
                'path': path, 
                'status': 'error', 
                'error': str(e)
            })
    
    # Resumen de operaciones
    stats = {
        'total': len(results),
        'success': sum(1 for r in results if r['status'] in ['created', 'updated', 'deleted', 'deleted_recursive', 'already_gone', 'kept_local', 'already_exists']),
        'errors': sum(1 for r in results if r['status'] == 'error'),
        'zombies_deleted': sum(1 for r in results if 'zombie' in r.get('reason', '') and r['status'] in ['deleted', 'deleted_recursive']),
        'kept_local': sum(1 for r in results if r.get('status') == 'kept_local')
    }
    
    print(f"[SYNC] Resumen: {stats}")
    
    return {'status': 'ok', 'results': results, 'stats': stats}

def handle_delta_confirmation(message):
    """
    Maneja confirmaciones de que un nodo complet√≥ su append.
    """
    delta_path = message.get('delta_path')
    node_ip = message.get('node_ip')
    status = message.get('status')
    target_path = message.get('target_path')
    
    print(f"[DELTA-CONFIRM] Confirmaci√≥n recibida de {node_ip} para {delta_path}")
    print(f"[DELTA-CONFIRM]   - Target: {target_path}")
    print(f"[DELTA-CONFIRM]   - Status: {status}")

    from ftp.commands import confirm_delta_transfer

    if status == 'success':
        # Marcar nodo como completado
        all_done = confirm_delta_transfer(delta_path, node_ip)
        
        if all_done:
            print(f"[DELTA-CONFIRM] Todas las r√©plicas confirmaron para {delta_path}")
        else:
            print(f"[DELTA-CONFIRM] A√∫n esperando confirmaciones de otros nodos")
    else:
        print(f"[DELTA-CONFIRM] Nodo {node_ip} report√≥ fallo en append")
        # A√∫n marcar como completado para no bloquear la limpieza
        confirm_delta_transfer(delta_path, node_ip)
    
    return {'status': 'ok'}

def handle_request_disk_scan(message):
    """
    Responde con un escaneo completo del sistema de archivos local.
    Esto permite al l√≠der detectar zombies que el log no reporta.
    """
    try:
        root_path = message.get('root_path', '/app/server/data')
        
        print(f"[SIDECAR] Escaneando disco en {root_path}...")
        
        sm = get_state_manager()
        disk_scan = sm.scan_local_filesystem(root_path)
        
        print(f"[SIDECAR] Escaneo completado: {len(disk_scan)} elementos encontrados")
        
        return {
            'status': 'ok',
            'disk_scan': disk_scan,
            'scan_timestamp': time.time(),
            'root_path': root_path
        }
    except Exception as e:
        print(f"[SIDECAR] Error en escaneo de disco: {e}")
        import traceback
        traceback.print_exc()
        return {
            'status': 'error',
            'message': str(e)
        }

def handle_replica_success(message):
        """Actualiza el estado global cuando una r√©plica es exitosa."""
        path = message.get('path')
        node_ip = message.get('node_ip')
        
        if _bully_instance and _bully_instance.am_i_leader():
            state_mgr = get_state_manager()
            with state_mgr.lock:
                if path in state_mgr.file_map:
                    if node_ip not in state_mgr.file_map[path].get('replicas', []):
                        state_mgr.file_map[path]['replicas'].append(node_ip)
                        print(f"[LIDER] R√©plica a√±adida: {node_ip} para {path}")
        
        return {'status': 'ok'}

# --- HILOS SECUNDARIOS ---

def update_ips_callback(new_ips):
        global _cluster_comm_global, _bully_instance
        
        old_ips = set(_cluster_comm_global.cluster_ips)
        new_ips_set = set(new_ips)
        
        added_ips = new_ips_set - old_ips
        removed_ips = old_ips - new_ips_set
        
        _cluster_comm_global.update_cluster_ips(new_ips)
        _bully_instance.update_nodes(new_ips)
        
        # Si soy l√≠der, gestionar fallos de nodos
        if _bully_instance and _bully_instance.am_i_leader():
            # Para cada nodo que ha salido, manejar su falla
            for failed_ip in removed_ips:
                print(f"[SIDECAR] Nodo {failed_ip} ha salido del cluster, iniciando recuperaci√≥n...")
                handle_node_failure(failed_ip)
            
            # Para cada nodo que ha entrado, verificar si necesita r√©plicas
            for new_ip in added_ips:
                print(f"[SIDECAR] Nodo {new_ip} ha entrado, verificando r√©plicas necesarias...")
                # Llamar a la funci√≥n correcta
                handle_node_join(new_ip)
        
        if added_ips:
            print(f"[SIDECAR] Nodos a√±adidos: {added_ips}")
        if removed_ips:
            print(f"[SIDECAR] Nodos removidos: {removed_ips}")

def start_replication_checker():
        """Verifica peri√≥dicamente el estado de replicaci√≥n."""
        while True:
            time.sleep(60)  # Verificar cada 60 segundos
            
            if _bully_instance and _bully_instance.am_i_leader():
                ops = get_leader_operations()
                if ops:
                    ops.check_replication_status()

def start_periodic_zombie_cleanup():
    """
    Ejecuta garbage collection completo cada 5 minutos.
    Esto limpia archivos y directorios obsoletos en TODO el cluster.
    """
    while True:
        time.sleep(300)  # 5 minutos
        
        if _bully_instance and _bully_instance.am_i_leader():
            # Verificar que no estamos reconstruyendo
            if _bully_instance.is_reconstructing():
                print("[SIDECAR] GC diferido: L√≠der a√∫n reconstruyendo estado")
                continue
            
            print("[SIDECAR] Ejecutando garbage collection peri√≥dico global...")
            
            try:
                from ftp.leader_operations import get_leader_operations
                ops = get_leader_operations()
                
                if ops:
                    ops.run_garbage_collection()
                else:
                    print("[SIDECAR] No se pudo obtener LeaderOperations para GC")
                    
            except Exception as e:
                print(f"[SIDECAR] Error en garbage collection peri√≥dico: {e}")
                import traceback
                traceback.print_exc()

# --- FUNCIONES COMPLEMENTARIAS ---

def handle_node_failure(failed_ip: str):
    """Maneja la falla de un nodo y coordina la replicaci√≥n de sus archivos."""
    print(f"[SIDECAR] Manejando falla del nodo: {failed_ip}")
    
    # Si soy el l√≠der, reasignar r√©plicas
    bully = get_global_bully()
    cluster_comm = get_global_cluster_comm()
    
    if not bully or not cluster_comm:
        print(f"[SIDECAR] No se puede manejar falla del nodo: cluster no inicializado")
        return
    
    if bully.am_i_leader():
        ops = get_leader_operations()
        if ops:
            # Usar el m√©todo handle_node_failure de LeaderOperations
            ops.handle_node_failure(failed_ip)
    else:
        print(f"[SIDECAR] No soy l√≠der, no manejo fallas de nodos")

def _handle_file_rename(old_path, new_path, operation_id, message):
    """Maneja el renombrado de archivos."""
    # Verificar si el archivo existe localmente
    if os.path.exists(old_path):
        # Verificar que el destino no exista
        if os.path.exists(new_path):
            print(f"[ORDER] ERROR: El archivo destino ya existe: {new_path}")
            return False
        
        # Crear directorios padres si es necesario
        os.makedirs(os.path.dirname(new_path), exist_ok=True)
        
        # Renombrar archivo
        try:
            os.rename(old_path, new_path)
            print(f"[ORDER] Archivo renombrado: {old_path} -> {new_path}")
            return True
        except OSError as e:
            # Capturamos espec√≠ficamente "Text file busy" (Errno 26 en Linux)
            if e.errno == 26 or "Text file busy" in str(e):
                print(f"[ORDER] ERROR: El archivo {old_path} est√° siendo usado (ETXTBSY). Abortando rename.")
            else:
                print(f"[ORDER] Error de OS al renombrar: {e}")
            
            # Retornamos False para que el L√≠der sepa que fall√≥
            return False 

    else:
        # El archivo no existe localmente - verificar si somos una r√©plica
        state_mgr = get_state_manager()
        file_info = state_mgr.get_file_info(old_path)
        
        if file_info and _cluster_comm_global.local_ip in file_info.get('replicas', []):
            # Somos una r√©plica pero el archivo no existe localmente
            print(f"[ORDER] INCONSISTENCIA: Somos r√©plica de {old_path} pero no lo tenemos")
            
            # Intentar descargar de otra r√©plica
            replicas = file_info.get('replicas', [])
            source_replicas = [ip for ip in replicas if ip != _cluster_comm_global.local_ip]
            
            if source_replicas:
                from ftp.node_transfer import get_node_transfer
                transfer = get_node_transfer()
                
                for source_ip in source_replicas:
                    print(f"[ORDER] Intentando descargar {old_path} desde {source_ip}")
                    success, _, _ = transfer.request_file_from_node(source_ip, old_path, old_path)
                    
                    if success:
                        # Ahora renombrar
                        try:
                            os.rename(old_path, new_path)
                            print(f"[ORDER] Archivo renombrado: {old_path} -> {new_path}")
                            return True
                        except OSError as e:
                            # Capturamos espec√≠ficamente "Text file busy" (Errno 26 en Linux)
                            if e.errno == 26 or "Text file busy" in str(e):
                                print(f"[ORDER] ERROR: El archivo {old_path} est√° siendo usado (ETXTBSY). Abortando rename.")
                            else:
                                print(f"[ORDER] Error de OS al renombrar: {e}")
                            
                            # Retornamos False para que el L√≠der sepa que fall√≥
                            return False 
        
        # No somos r√©plica o no pudimos descargar
        print(f"[ORDER] No somos r√©plica de {old_path}, solo actualizamos estado")
        return True  # Devolvemos True porque actualizamos el estado aunque no tengamos el archivo

def _handle_directory_rename(old_path, new_path, operation_id):
    """Maneja el renombrado de directorios con limpieza mejorada."""
    print(f"[ORDER] Renombrando directorio: {old_path} -> {new_path}")
    
    # Verificar si el directorio existe localmente
    if os.path.exists(old_path):
        # Crear directorio destino si no existe
        os.makedirs(os.path.dirname(new_path), exist_ok=True)
        
        # Verificar que el destino no exista
        if os.path.exists(new_path):
            print(f"[ORDER] ERROR: El directorio destino ya existe: {new_path}")
            
            # Si el destino existe, puede ser por un renombrado previo
            # Comparar contenidos para ver si son el mismo
            try:
                old_contents = set(os.listdir(old_path)) if os.path.isdir(old_path) else set()
                new_contents = set(os.listdir(new_path)) if os.path.isdir(new_path) else set()
                
                if old_contents == new_contents:
                    print(f"[ORDER] Los directorios tienen el mismo contenido, eliminando antiguo")
                    shutil.rmtree(old_path)
                    return True
            except Exception as e:
                print(f"[ORDER] Error comparando directorios: {e}")
            
            return False
        
        # Renombrar directorio (mueve todo el contenido)
        try:
            os.rename(old_path, new_path)
            print(f"[ORDER] Directorio renombrado: {old_path} -> {new_path}")
            
            # Verificar que el antiguo ya no existe
            if os.path.exists(old_path):
                print(f"[ORDER] ADVERTENCIA: Directorio antiguo a√∫n existe despu√©s de rename")
                # Intentar limpiarlo
                try:
                    if os.path.isdir(old_path) and not os.listdir(old_path):
                        os.rmdir(old_path)
                except:
                    pass
            
            return True
        except OSError as e:
            print(f"[ORDER] Error de OS al renombrar directorio: {e}")
            return False
    else:
        # El directorio no existe localmente, pero debemos crearlo vac√≠o
        # Esto es necesario para mantener la estructura de directorios
        print(f"[ORDER] Directorio {old_path} no existe localmente, creando {new_path}")
        
        try:
            # Crear el nuevo directorio (vac√≠o)
            os.makedirs(new_path, exist_ok=True)
            
            # Verificar si la estructura antigua existe en alguna variaci√≥n
            # (puede haber quedado de un renombrado previo incompleto)
            old_normalized = old_path.rstrip('/')
            
            # Buscar directorios similares que puedan ser versiones antiguas
            parent_dir = os.path.dirname(old_normalized)
            if os.path.exists(parent_dir):
                try:
                    for item in os.listdir(parent_dir):
                        full_item_path = os.path.join(parent_dir, item)
                        if full_item_path.startswith(old_normalized) and full_item_path != new_path:
                            print(f"[ORDER] Detectada posible estructura antigua: {full_item_path}")
                            # No eliminar autom√°ticamente, solo reportar
                except Exception as e:
                    print(f"[ORDER] Error buscando estructuras antiguas: {e}")
            
            return True
        except Exception as e:
            print(f"[ORDER] Error creando directorio: {e}")
            return False
